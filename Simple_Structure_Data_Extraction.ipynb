{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Document Extraction with LLMs\n",
    "\n",
    "This notebook demonstrates the basic components for extracting structured information from documents using LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, let's install and import the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install langchain langchain_openai pydantic python-dotenv pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set your OpenAI API key\n",
    "# You can either set it in your environment or directly here\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\", \"your-api-key-here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the Schema\n",
    "\n",
    "Let's create a simple schema for extracting information from a CV/resume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a simple schema for CV extraction\n",
    "class Experience(BaseModel):\n",
    "    \"\"\"Work experience information\"\"\"\n",
    "    company: str = Field(..., description=\"Company name\")\n",
    "    position: str = Field(..., description=\"Job title\")\n",
    "    period: str = Field(..., description=\"Employment period (e.g., '2019-2021')\")\n",
    "    description: str = Field(..., description=\"Job description and responsibilities\")\n",
    "\n",
    "class Education(BaseModel):\n",
    "    \"\"\"Educational background\"\"\"\n",
    "    institution: str = Field(..., description=\"School or university name\")\n",
    "    degree: str = Field(..., description=\"Degree obtained\")\n",
    "    year: str = Field(..., description=\"Graduation year\")\n",
    "\n",
    "class CVSchema(BaseModel):\n",
    "    \"\"\"Basic CV/resume schema\"\"\"\n",
    "    name: str = Field(..., description=\"Full name of the person\")\n",
    "    summary: str = Field(..., description=\"Professional summary or objective\")\n",
    "    experience: List[Experience] = Field(default_factory=list, description=\"Work experience\")\n",
    "    education: List[Education] = Field(default_factory=list, description=\"Educational background\")\n",
    "    skills: List[str] = Field(default_factory=list, description=\"Professional skills\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load a Document\n",
    "\n",
    "Now let's load a document (PDF in this example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document loaded successfully! Length: 1981 characters\n",
      "Preview: Oscar Quiroga\n",
      "MATHEMATICIAN \n",
      "quipios@gmail.com\n",
      "Bogot√°, Colombia\n",
      "Mathematician with management experience, responsible fordata analysis and reporting to support decision-making. Problem-solving and cri...\n"
     ]
    }
   ],
   "source": [
    "def load_document(file_path):\n",
    "    \"\"\"Load a PDF document\"\"\"\n",
    "    try:\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        documents = loader.load()\n",
    "        \n",
    "        # Combine all pages into a single text\n",
    "        text = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading document: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage - replace with your document path\n",
    "document_path = \"C:\\\\Users\\\\Oscar\\\\CascadeProjects\\\\RAGs\\\\cv_extractor\\\\documents_folder\\\\cv\\\\001.pdf\"  # Replace with your file path\n",
    "\n",
    "# Load the document\n",
    "document_text = load_document(document_path)\n",
    "\n",
    "if document_text:\n",
    "    print(f\"Document loaded successfully! Length: {len(document_text)} characters\")\n",
    "    print(f\"Preview: {document_text[:200]}...\")\n",
    "else:\n",
    "    print(\"Failed to load document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create the Extraction Function\n",
    "\n",
    "Let's create a function to extract structured data using an LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_information(text, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"Extract structured information from text using an LLM\"\"\"\n",
    "    # Create the LLM\n",
    "    llm = ChatOpenAI(model=model, temperature=0)\n",
    "    \n",
    "    # Create a prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"\n",
    "        Extract structured information from the CV/resume according to the schema.\n",
    "        Only extract information that is explicitly mentioned in the text.\n",
    "        Do not make up or infer information that is not present.\n",
    "        \"\"\"),\n",
    "        (\"human\", \"{text}\")\n",
    "    ])\n",
    "    \n",
    "    # Create the extraction chain\n",
    "    chain = prompt | llm.with_structured_output(CVSchema)\n",
    "    \n",
    "    # Run the extraction\n",
    "    try:\n",
    "        result = chain.invoke({\"text\": text})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error during extraction: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract and Display Results\n",
    "\n",
    "Now let's extract information from our document and display the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting information...\n",
      "\n",
      "Extracted Information:\n",
      "Name: Oscar Quiroga\n",
      "Summary: Mathematician with management experience, responsible for data analysis and reporting to support decision-making. Problem-solving and critical thinking capabilities.\n",
      "\n",
      "Experience:\n",
      "- Tech Manager - Corporate Security at BBVA (2019-2021)\n",
      "- Intelligence Analyst at Presidencia de Colombia (2012-2018)\n",
      "- Smart Contract Developer at OnAnalytics (2021-2024)\n",
      "\n",
      "Education:\n",
      "- Mathematics from Pontifical Xaverian University (2004-2009)\n",
      "\n",
      "Skills:\n",
      "- Data Analysis\n",
      "- Data Visualization\n",
      "- Spreadsheets\n",
      "- SQL\n",
      "- Data Studio\n",
      "- Tableau\n",
      "- Python\n",
      "- Google Suite\n",
      "- Dune Analytics\n",
      "- Block Explorers\n",
      "- DexScreener\n",
      "- Token Terminal\n",
      "- Arkham Intelligence\n",
      "- Web3 - Industry knowledge\n",
      "\n",
      "JSON Output:\n",
      "{\n",
      "  \"name\": \"Oscar Quiroga\",\n",
      "  \"summary\": \"Mathematician with management experience, responsible for data analysis and reporting to support decision-making. Problem-solving and critical thinking capabilities.\",\n",
      "  \"experience\": [\n",
      "    {\n",
      "      \"company\": \"BBVA\",\n",
      "      \"position\": \"Tech Manager - Corporate Security\",\n",
      "      \"period\": \"2019-2021\",\n",
      "      \"description\": \"Team Leader specializing in Corporate Security, responsible for delivering reports, dashboards, and in-depth analyses. Adept at developing and implementing KPIs related to fraud and cybersecurity for senior executives. Experienced in building operational and strategic dashboards to enhance decision-making and support security initiatives.\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"Presidencia de Colombia\",\n",
      "      \"position\": \"Intelligence Analyst\",\n",
      "      \"period\": \"2012-2018\",\n",
      "      \"description\": \"Led the initiative to educate cross-functional teams on advanced analysis techniques for intelligence gathering. Played a pivotal role in building and implementing KPIs to assess the impact and effectiveness of products developed, ensuring alignment with strategic objectives.\"\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"OnAnalytics\",\n",
      "      \"position\": \"Smart Contract Developer\",\n",
      "      \"period\": \"2021-2024\",\n",
      "      \"description\": \"Details not provided.\"\n",
      "    }\n",
      "  ],\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"institution\": \"Pontifical Xaverian University\",\n",
      "      \"degree\": \"Mathematics\",\n",
      "      \"year\": \"2004-2009\"\n",
      "    }\n",
      "  ],\n",
      "  \"skills\": [\n",
      "    \"Data Analysis\",\n",
      "    \"Data Visualization\",\n",
      "    \"Spreadsheets\",\n",
      "    \"SQL\",\n",
      "    \"Data Studio\",\n",
      "    \"Tableau\",\n",
      "    \"Python\",\n",
      "    \"Google Suite\",\n",
      "    \"Dune Analytics\",\n",
      "    \"Block Explorers\",\n",
      "    \"DexScreener\",\n",
      "    \"Token Terminal\",\n",
      "    \"Arkham Intelligence\",\n",
      "    \"Web3 - Industry knowledge\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "Saved to: C:\\Users\\Oscar\\CascadeProjects\\RAGs\\cv_extractor\\documents_folder\\cv\\001_extracted.json\n"
     ]
    }
   ],
   "source": [
    "# Only run if we have document text\n",
    "if document_text:\n",
    "    # Extract information\n",
    "    print(\"Extracting information...\")\n",
    "    extracted_data = extract_information(document_text)\n",
    "    \n",
    "    if extracted_data:\n",
    "        # Display the extracted information\n",
    "        print(\"\\nExtracted Information:\")\n",
    "        print(f\"Name: {extracted_data.name}\")\n",
    "        print(f\"Summary: {extracted_data.summary}\")\n",
    "        \n",
    "        print(\"\\nExperience:\")\n",
    "        for exp in extracted_data.experience:\n",
    "            print(f\"- {exp.position} at {exp.company} ({exp.period})\")\n",
    "        \n",
    "        print(\"\\nEducation:\")\n",
    "        for edu in extracted_data.education:\n",
    "            print(f\"- {edu.degree} from {edu.institution} ({edu.year})\")\n",
    "        \n",
    "        print(\"\\nSkills:\")\n",
    "        for skill in extracted_data.skills:\n",
    "            print(f\"- {skill}\")\n",
    "            \n",
    "        # Convert to JSON and save\n",
    "        json_data = extracted_data.model_dump_json(indent=2)\n",
    "        \n",
    "        # Display JSON\n",
    "        print(\"\\nJSON Output:\")\n",
    "        print(json_data)\n",
    "        \n",
    "        # Save to file\n",
    "        output_path = document_path.replace(\".pdf\", \"_extracted.json\")\n",
    "        with open(output_path, \"w\") as f:\n",
    "            f.write(json_data)\n",
    "        print(f\"\\nSaved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Customize for Different Document Types\n",
    "\n",
    "You can easily customize this for different document types by changing the schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Invoice schema\n",
    "class InvoiceItem(BaseModel):\n",
    "    description: str\n",
    "    quantity: float\n",
    "    unit_price: float\n",
    "    amount: float\n",
    "\n",
    "class InvoiceSchema(BaseModel):\n",
    "    invoice_number: str\n",
    "    date: str\n",
    "    vendor: str\n",
    "    customer: str\n",
    "    items: List[InvoiceItem]\n",
    "    total_amount: float\n",
    "\n",
    "# To use this schema, you would just change the schema in the extract_information function:\n",
    "# chain = prompt | llm.with_structured_output(InvoiceSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "This notebook demonstrated the basic components of document extraction:\n",
    "\n",
    "1. Defining a schema with Pydantic\n",
    "2. Loading documents\n",
    "3. Creating an extraction function with LLMs\n",
    "4. Generating structured output\n",
    "\n",
    "You can extend this by adding support for more document types, improving the extraction prompt, or adding post-processing for the extracted data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
